{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo2k8b1yW9Y705+VYzOIOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demigod-22/CV-Buddy/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wi6SKDOyFwR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dWWIZYptyYde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a knowledge distillation class"
      ],
      "metadata": {
        "id": "NIpMh5aOymX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers.optimizer_v1 import Optimizer\n",
        "class K_Distillation(keras.Model):\n",
        "  def __init__(self,student,teacher):\n",
        "    super().__init__()\n",
        "    self.student = student\n",
        "    self.teacher = teacher\n",
        "\n",
        "\n",
        "  def compile(self,optimizer,st_loss_fn,k_distillation_loss_fn,alpha = 0.1,temperature = 3,metrics):\n",
        "    super().compile(optimizer = optimizer,metrics = metrics)\n",
        "    self.st_loss_fn = st_loss_fn\n",
        "    self.k_distillation_loss_fn = k_distillation_loss_fn\n",
        "    self.alpha = alpha\n",
        "    self.temperature  = temperature\n",
        "\n",
        "  def train(self,dataset):\n",
        "\n",
        "    x,y = dataset\n",
        "\n",
        "    teacher_predictions = self.teacher(x)\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      st_predictions = self.student(x)\n",
        "\n",
        "      st_loss = self.st_loss_fn(y, st_predictions)\n",
        "\n",
        "      k_distillation_loss = (self.k_distillation_loss_fn(tf.nn.softmax(teacher_predictions / self.temperature, axis=1),tf.nn.softmax(st_predictions / self.temperature, axis=1),)* self.temperature**2)\n",
        "\n",
        "      loss = self.alpha * st_loss + (1 - self.alpha) * k_distillation_loss\n",
        "\n",
        "        \n",
        "      trainable_vars = self.student.trainable_variables\n",
        "      gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "      \n",
        "      self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "      \n",
        "      self.compiled_metrics.update_state(y, st_predictions)\n",
        "\n",
        "    \n",
        "      results = {m.name: m.result() for m in self.metrics}\n",
        "      results.update({\"student_loss\": st_loss, \"distillation_loss\": k_distillation_loss})\n",
        "      return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        \n",
        "        x, y = data\n",
        "\n",
        "        \n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        st_loss = self.st_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": st_loss})\n",
        "        return results"
      ],
      "metadata": {
        "id": "UqEyKSl_ydob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller = K_Distillation(student = st_model,teacher)\n",
        "distiller.compile(optimizer = 'adam',st_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy, k_distillation_loss_fn=tf.keras.losses.KLDivergence,alpha = 0.1 , temperature = 10,metrics = [keras.metrics.SparseCategoricalAccuracy])"
      ],
      "metadata": {
        "id": "FPdS1yDZDG7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_model = models.Sequential()\n",
        "st_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "st_model.add(layers.MaxPooling2D((2, 2)))\n",
        "st_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "st_model.add(layers.MaxPooling2D((2, 2)))\n",
        "st_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "st_model.add(layers.Flatten())\n",
        "st_model.add(layers.Dense(64,activation = 'relu'))"
      ],
      "metadata": {
        "id": "nKyTTBJc39IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puJ2obBn4u3g",
        "outputId": "dcc53e9c-b485-4dc5-a3fa-a742ec575d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                65600     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,920\n",
            "Trainable params: 121,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5 \n",
        "st_model.add(layers.Dense(k))"
      ],
      "metadata": {
        "id": "ILEZkaP0495t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_model.compile(optimizer = 'adam' , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_Logits = True) )"
      ],
      "metadata": {
        "id": "LaIMxEdh5kDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st1_model = keras.models.clone_model(st_model)"
      ],
      "metadata": {
        "id": "-IVvrQQG53JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vlePgUXYsK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model1, model2, model3]\n",
        "preds1 = [model.predict(X_test) for model in models]\n",
        "preds1=np.array(preds1)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([])\n",
        "\n",
        "for w1 in range(0, 5):\n",
        "    for w2 in range(0,5):\n",
        "        for w3 in range(0,5):\n",
        "            wts = [w1/10.,w2/10.,w3/10.]\n",
        "            wted_preds1 = np.tensordot(preds1, wts, axes=((0),(0)))\n",
        "            wted_ensemble_pred = np.argmax(wted_preds1, axis=1)\n",
        "            weighted_accuracy = accuracy_score(y_test, wted_ensemble_pred)\n",
        "            df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1], \n",
        "                                         'wt3':wts[2], 'acc':weighted_accuracy*100}, index=[0]), ignore_index=True)\n",
        "            \n",
        "max_acc_row = df.iloc[df['acc'].idxmax()]\n",
        "print(\"Max accuracy of \", max_acc_row[0], \" obained with w1=\", max_acc_row[1],\n",
        "      \" w2=\", max_acc_row[2], \" and w3=\", max_acc_row[3])"
      ],
      "metadata": {
        "id": "7WnApFeq6O7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}